import pandas as pd
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix


def calculate_accuracy(predictions_file, true_labels_file, threshold=0.5):
    try:
        # Load predictions (assumes predictions are in the same order as true labels)
        predictions_df = pd.read_csv(predictions_file)

        # Load true labels
        true_labels_df = pd.read_csv(true_labels_file)

        # Check if the number of rows matches
        if len(predictions_df) != len(true_labels_df):
            raise ValueError(
                "The number of predictions does not match the number of true labels")

        # Apply threshold to convert probabilities to binary labels
        binary_predictions = (
            predictions_df['HasDetections'] > threshold).astype(int)

        # Calculate accuracy
        accuracy = accuracy_score(
            true_labels_df['HasDetections'], binary_predictions)

        # Additional metrics
        report = classification_report(
            true_labels_df['HasDetections'], binary_predictions)
        confusion = confusion_matrix(
            true_labels_df['HasDetections'], binary_predictions)

        return accuracy, report, confusion

    except Exception as e:
        return str(e)


# Define file paths
predictions_file = 'Result/result_lgbm.csv'
true_labels_file = 'Data/y_test_encoded.csv'

# Calculate and print accuracy and other metrics
accuracy, report, confusion = calculate_accuracy(
    predictions_file, true_labels_file)
print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:")
print(report)
print("Confusion Matrix:")
print(confusion)
